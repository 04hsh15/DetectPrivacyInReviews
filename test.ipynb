{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\model\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\model\\mrcnn\\model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\model\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\model\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\model\\mrcnn\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\model\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "from model.mrcnn import utils\n",
    "import model.mrcnn.model as modellib\n",
    "from model.mrcnn import visualize\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from model.coco import coco2\n",
    "import warnings\n",
    "\n",
    "import json\n",
    "import io\n",
    "import requests\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\") #현재 경로\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# 모델 불러오기    \n",
    "class InferenceConfig(coco2.CocoConfig): # 'coco.py'의 'CocoConfig' 클래스\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "config = InferenceConfig()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_masking(model, input,test_folder_path): # \n",
    "        out_list = []\n",
    "        # COCO Class names\n",
    "        class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "                    'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "                    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "                    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "                    'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                    'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "                    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                    'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "        # 'test_folder' 내부의 파일 목록을 가져옴\n",
    "\n",
    "        for filename in input:\n",
    "            print(filename)\n",
    "            \n",
    "            image = skimage.io.imread(os.path.join(test_folder_path, filename))\n",
    "\n",
    "            # Check if the image has 4 channels (RGBA) and convert it to RGB\n",
    "            if image.shape[2] == 4:\n",
    "                image = Image.fromarray(image)\n",
    "                image = image.convert('RGB')\n",
    "                image = np.array(image)\n",
    "\n",
    "            results= model.detect([image],verbose=0)\n",
    "            \n",
    "            r = results[0]\n",
    "\n",
    "            # 임계값 설정\n",
    "            threshold = 0.9\n",
    "\n",
    "            indices_to_keep = np.where(r['scores'] > threshold)[0]\n",
    "\n",
    "            # 선택한 인덱스에 해당하는 masks, scores, class_ids를 가져옵니다.\n",
    "            r['masks'] = r['masks'][:, :, indices_to_keep]\n",
    "            r['scores'] = r['scores'][indices_to_keep]\n",
    "            r['class_ids'] = r['class_ids'][indices_to_keep]\n",
    "\n",
    "            masks = r['masks'][:, :, r['class_ids'] == 1]  # 사람인 경우\n",
    "            \n",
    "            if not masks.size > 0:\n",
    "                print('NO person!!')\n",
    "                out_list.append(filename)\n",
    "            else:\n",
    "                mask = np.sum(masks, axis=2).astype(np.bool)  # 채널 하나짜리 마스크\n",
    "                # 확장된 마스크 생성\n",
    "                kernel = np.ones((25, 25), np.uint8)  # 팽창 연산에 사용될 커널 설정\n",
    "                expanded_mask = cv2.dilate(mask.astype(np.uint8), kernel, iterations=1)\n",
    "                expanded_mask = expanded_mask.astype(np.bool)\n",
    "                mask_3d = np.repeat(np.expand_dims(expanded_mask, axis=2), 3, axis=2).astype(np.uint8)  # 채널 3짜리 마스크\n",
    "\n",
    "                # 이미지 블러 처리\n",
    "                blurred_img = cv2.GaussianBlur(image, (101, 101), 125)\n",
    "                mask_3d_blurred = (cv2.GaussianBlur(mask_3d*255,(101,101),10,10)/255).astype(np.float32)\n",
    "\n",
    "                # mix it together\n",
    "                person_mask = mask_3d_blurred * image.astype(np.float32)\n",
    "                bg_mask = (1 - mask_3d_blurred) * blurred_img.astype(np.float32)\n",
    "                out = (person_mask + bg_mask).astype(np.uint8)\n",
    "                out_image = out.astype(np.uint8)\n",
    "                \n",
    "                bgr_image = cv2.cvtColor(out_image, cv2.COLOR_RGB2BGR) # 최종본!\n",
    "                print(filename, 'finish!') # 잘되는지 안되는지 확인\n",
    "                \n",
    "                #img_name = 'img'+ str(NUM) + '.jpg'\n",
    "                output_path = os.path.join(test_folder_path,'back', filename) #위에서 정의한 경로에 filname으로 저장하기 위한 코드\n",
    "                cv2.imwrite(output_path, bgr_image)# 아웃풋 폴\n",
    "            \n",
    "                out_list.append(output_path)\n",
    "                print('output_path',output_path)\n",
    "\n",
    "        return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hOMe_pc\\\\Code\\\\AIs\\\\server\\\\FlaskTest\\\\test_folder'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 현재 디렉토리 위치\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 이미지 파일을 저장할 배열\n",
    "image_names = []\n",
    "\n",
    "# 'test_folder' 경로\n",
    "test_folder_path = os.path.join(current_directory, 'test_folder')\n",
    "\n",
    "# 'test_folder' 내부의 파일 목록을 가져옴\n",
    "if os.path.exists(test_folder_path) and os.path.isdir(test_folder_path):\n",
    "    image_names = [f for f in os.listdir(test_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "image_names\n",
    "test_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1.jpeg\n",
      "a1.jpeg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\a1.jpeg\n",
      "c1.jpg\n",
      "c1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\c1.jpg\n",
      "c2.jpg\n",
      "c2.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\c2.jpg\n",
      "ive1.jpg\n",
      "ive1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\ive1.jpg\n",
      "j.jpg\n",
      "j.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\j.jpg\n",
      "jan1.jpg\n",
      "jan1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jan1.jpg\n",
      "jo1.jpg\n",
      "jo1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo1.jpg\n",
      "jo2.png\n",
      "jo2.png finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo2.png\n",
      "jo3.jpg\n",
      "jo3.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo3.jpg\n",
      "jo4.jpg\n",
      "jo4.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo4.jpg\n",
      "jo5.jpg\n",
      "jo5.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo5.jpg\n",
      "jo6.jpg\n",
      "jo6.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo6.jpg\n",
      "lee1.jpg\n",
      "lee1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\lee1.jpg\n",
      "lee3.jpg\n",
      "lee3.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\lee3.jpg\n",
      "new1.jpg\n",
      "new1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\new1.jpg\n",
      "park1.jpg\n",
      "park1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\park1.jpg\n",
      "s1.jpg\n",
      "s1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\s1.jpg\n",
      "suji.jpg\n",
      "suji.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji.jpg\n",
      "suji2.jpg\n",
      "suji2.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji2.jpg\n",
      "suji4.jpg\n",
      "suji4.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji4.jpg\n",
      "suji5.jpg\n",
      "suji5.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji5.jpg\n",
      "suji6.jpg\n",
      "suji6.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji6.jpg\n",
      "sun1.jpg\n",
      "sun1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\sun1.jpg\n",
      "y1.jpg\n",
      "y1.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\y1.jpg\n",
      "y2.jpg\n",
      "y2.jpg finish!\n",
      "output_path c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\y2.jpg\n"
     ]
    }
   ],
   "source": [
    "out_list = background_masking(model, image_names, test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\hOMe_pc\\Anaconda3\\envs\\AIS_mrcnn\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Use MobileNet as backbone\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from face_model.common.utils import BBox, drawLandmark, drawLandmark_multiple\n",
    "from face_model.models.basenet import MobileNet_GDConv\n",
    "from face_model.blur.bluring import total_blur\n",
    "from PIL import Image\n",
    "from face_model.MTCNN import detect_faces\n",
    "from face_model.utils.align_trans import get_reference_facial_points, warp_and_crop_face\n",
    "\n",
    "import json\n",
    "import io\n",
    "import requests\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    map_location = lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    map_location = 'cpu'\n",
    "    \n",
    "model_f = MobileNet_GDConv(136)\n",
    "model_f = torch.nn.DataParallel(model_f)\n",
    "checkpoint_path = 'face_model/checkpoint/mobilenet_224_model_best_gdconv_external.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=map_location)\n",
    "print(map_location)\n",
    "print('Use MobileNet as backbone')\n",
    "model_f.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hOMe_pc\\\\Code\\\\AIs\\\\server\\\\FlaskTest\\\\test_folder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 현재 디렉토리 위치\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 이미지 파일을 저장할 배열\n",
    "image_names = []\n",
    "\n",
    "# 'test_folder' 경로\n",
    "test_folder_path = os.path.join(current_directory, 'test_folder')\n",
    "\n",
    "# 'test_folder' 내부의 파일 목록을 가져옴\n",
    "if os.path.exists(test_folder_path) and os.path.isdir(test_folder_path):\n",
    "    image_names = [f for f in os.listdir(test_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "image_names\n",
    "test_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_model.MTCNN import detect_faces\n",
    "\n",
    "\n",
    "def face_masking(model, input ,test_folder_path): #\n",
    "    mean = np.asarray([0.485, 0.456, 0.406])\n",
    "    std = np.asarray([0.229, 0.224, 0.225])\n",
    "    out_size = 224\n",
    "    crop_size = 112\n",
    "    scale = crop_size / 112.\n",
    "    reference = get_reference_facial_points(default_square=True) * scale\n",
    "    model = model.eval()\n",
    "    # 이미지 파일 순회 및 처리\n",
    "    for file_name in input:\n",
    "        print(os.path.join(test_folder_path, file_name))\n",
    "        img = cv2.imread(os.path.join(test_folder_path, file_name))\n",
    "        \n",
    "        \n",
    "        height, width, _ = img.shape\n",
    "        ##detector\n",
    "        image = Image.open(os.path.join(test_folder_path, file_name))\n",
    "        # Check if the image has 4 channels (RGBA) and convert it to RGB\n",
    "        if image.mode == \"RGBA\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        faces, landmarks = detect_faces(image)\n",
    "\n",
    "\n",
    "        if len(landmarks) == 0:\n",
    "            print('NO face is detected!')\n",
    "            \n",
    "        if len(faces) == 0:\n",
    "            print('NO face is detected!')\n",
    "            \n",
    "        else:\n",
    "            # Initialize an empty list to store landmarks\n",
    "            all_landmarks = []\n",
    "\n",
    "            for k, face in enumerate(faces):\n",
    "                if face[4] < 0.9:  # remove low confidence detection\n",
    "                    continue\n",
    "                x1 = face[0]\n",
    "                y1 = face[1]\n",
    "                x2 = face[2]\n",
    "                y2 = face[3]\n",
    "                w = x2 - x1 + 1\n",
    "                h = y2 - y1 + 1\n",
    "                size = int(min([w, h]) * 1.2)\n",
    "                cx = x1 + w // 2\n",
    "                cy = y1 + h // 2\n",
    "                x1 = cx - size // 2\n",
    "                x2 = x1 + size\n",
    "                y1 = cy - size // 2\n",
    "                y2 = y1 + size\n",
    "\n",
    "                dx = max(0, -x1)\n",
    "                dy = max(0, -y1)\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "\n",
    "                edx = max(0, x2 - width)\n",
    "                edy = max(0, y2 - height)\n",
    "                x2 = min(width, x2)\n",
    "                y2 = min(height, y2)\n",
    "                new_bbox = list(map(int, [x1, x2, y1, y2]))\n",
    "                new_bbox = BBox(new_bbox)\n",
    "                cropped = img[new_bbox.top:new_bbox.bottom, new_bbox.left:new_bbox.right]\n",
    "                if (dx > 0 or dy > 0 or edx > 0 or edy > 0):\n",
    "                    cropped = cv2.copyMakeBorder(cropped, int(dy), int(edy), int(dx), int(edx), cv2.BORDER_CONSTANT, 0)\n",
    "                cropped_face = cv2.resize(cropped, (out_size, out_size))\n",
    "\n",
    "                if cropped_face.shape[0] <= 0 or cropped_face.shape[1] <= 0:\n",
    "                    continue\n",
    "                test_face = cropped_face.copy()\n",
    "                test_face = test_face / 255.0\n",
    "                test_face = (test_face - mean) / std\n",
    "                test_face = test_face.transpose((2, 0, 1))\n",
    "                test_face = test_face.reshape((1,) + test_face.shape)\n",
    "                input = torch.from_numpy(test_face).float()\n",
    "                input = torch.autograd.Variable(input)\n",
    "                \n",
    "                landmark = model(input).cpu().data.numpy()\n",
    "                \n",
    "                landmark = landmark.reshape(-1, 2)\n",
    "                landmark = new_bbox.reprojectLandmark(landmark)\n",
    "                \n",
    "                # Append the landmarks to the list\n",
    "                all_landmarks.append(landmark)\n",
    "            \n",
    "            # Draw landmarks on the original image\n",
    "            for landmarks in all_landmarks:\n",
    "                \n",
    "                img = total_blur(img, landmarks)\n",
    "            \n",
    "             #img_name = 'img'+ str(NUM) + '.jpg'\n",
    "            output_path = os.path.join(test_folder_path,'face', file_name) #위에서 정의한 경로에 filname으로 저장하기 위한 코드\n",
    "            cv2.imwrite(output_path, img)# 아웃풋 저장 덮어씌우기\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\a1.jpeg\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\c1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\c2.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\ive1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\j.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\jan1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\jo1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\jo2.png\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\jo3.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\jo4.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\jo5.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\jo6.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\lee1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\lee3.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\new1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\park1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\s1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\suji.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\suji2.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\suji4.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\suji5.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\suji6.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\sun1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\y1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\y2.jpg\n"
     ]
    }
   ],
   "source": [
    "face_masking(model_f, image_names ,test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hOMe_pc\\\\Code\\\\AIs\\\\server\\\\FlaskTest\\\\test_folder\\\\back'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 현재 디렉토리 위치\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 이미지 파일을 저장할 배열\n",
    "image_names = []\n",
    "\n",
    "# 'test_folder' 경로\n",
    "test_folder_path = os.path.join(current_directory, 'test_folder','back')\n",
    "\n",
    "# 'test_folder' 내부의 파일 목록을 가져옴\n",
    "if os.path.exists(test_folder_path) and os.path.isdir(test_folder_path):\n",
    "    image_names = [f for f in os.listdir(test_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "image_names\n",
    "test_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_model.MTCNN import detect_faces\n",
    "\n",
    "\n",
    "def face_masking(model, input ,test_folder_path): #\n",
    "    mean = np.asarray([0.485, 0.456, 0.406])\n",
    "    std = np.asarray([0.229, 0.224, 0.225])\n",
    "    out_size = 224\n",
    "    crop_size = 112\n",
    "    scale = crop_size / 112.\n",
    "    reference = get_reference_facial_points(default_square=True) * scale\n",
    "    model = model.eval()\n",
    "    # 이미지 파일 순회 및 처리\n",
    "    for file_name in input:\n",
    "        print(os.path.join(test_folder_path, file_name))\n",
    "        img = cv2.imread(os.path.join(test_folder_path, file_name))\n",
    "\n",
    "        \n",
    "        height, width, _ = img.shape\n",
    "        ##detector\n",
    "        image = Image.open(os.path.join(test_folder_path, file_name))\n",
    "        # Check if the image has 4 channels (RGBA) and convert it to RGB\n",
    "        if image.mode == \"RGBA\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        faces, landmarks = detect_faces(image)\n",
    "\n",
    "\n",
    "        if len(landmarks) == 0:\n",
    "            print('NO face is detected!')\n",
    "            \n",
    "        if len(faces) == 0:\n",
    "            print('NO face is detected!')\n",
    "            \n",
    "        else:\n",
    "            # Initialize an empty list to store landmarks\n",
    "            all_landmarks = []\n",
    "\n",
    "            for k, face in enumerate(faces):\n",
    "                if face[4] < 0.9:  # remove low confidence detection\n",
    "                    continue\n",
    "                x1 = face[0]\n",
    "                y1 = face[1]\n",
    "                x2 = face[2]\n",
    "                y2 = face[3]\n",
    "                w = x2 - x1 + 1\n",
    "                h = y2 - y1 + 1\n",
    "                size = int(min([w, h]) * 1.2)\n",
    "                cx = x1 + w // 2\n",
    "                cy = y1 + h // 2\n",
    "                x1 = cx - size // 2\n",
    "                x2 = x1 + size\n",
    "                y1 = cy - size // 2\n",
    "                y2 = y1 + size\n",
    "\n",
    "                dx = max(0, -x1)\n",
    "                dy = max(0, -y1)\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "\n",
    "                edx = max(0, x2 - width)\n",
    "                edy = max(0, y2 - height)\n",
    "                x2 = min(width, x2)\n",
    "                y2 = min(height, y2)\n",
    "                new_bbox = list(map(int, [x1, x2, y1, y2]))\n",
    "                new_bbox = BBox(new_bbox)\n",
    "                cropped = img[new_bbox.top:new_bbox.bottom, new_bbox.left:new_bbox.right]\n",
    "                if (dx > 0 or dy > 0 or edx > 0 or edy > 0):\n",
    "                    cropped = cv2.copyMakeBorder(cropped, int(dy), int(edy), int(dx), int(edx), cv2.BORDER_CONSTANT, 0)\n",
    "                cropped_face = cv2.resize(cropped, (out_size, out_size))\n",
    "\n",
    "                if cropped_face.shape[0] <= 0 or cropped_face.shape[1] <= 0:\n",
    "                    continue\n",
    "                test_face = cropped_face.copy()\n",
    "                test_face = test_face / 255.0\n",
    "                test_face = (test_face - mean) / std\n",
    "                test_face = test_face.transpose((2, 0, 1))\n",
    "                test_face = test_face.reshape((1,) + test_face.shape)\n",
    "                input = torch.from_numpy(test_face).float()\n",
    "                input = torch.autograd.Variable(input)\n",
    "                \n",
    "                landmark = model(input).cpu().data.numpy()\n",
    "                \n",
    "                landmark = landmark.reshape(-1, 2)\n",
    "                landmark = new_bbox.reprojectLandmark(landmark)\n",
    "                \n",
    "                # Append the landmarks to the list\n",
    "                all_landmarks.append(landmark)\n",
    "            \n",
    "            # Draw landmarks on the original image\n",
    "            for landmarks in all_landmarks:\n",
    "                \n",
    "                img = total_blur(img, landmarks)\n",
    "            \n",
    "             #img_name = 'img'+ str(NUM) + '.jpg'\n",
    "            output_path = os.path.join(test_folder_path,'total', file_name) #위에서 정의한 경로에 filname으로 저장하기 위한 코드\n",
    "            cv2.imwrite(output_path, img)# 아웃풋 저장 덮어씌우기\n",
    "            print(output_path)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\a1.jpeg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\a1.jpeg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\c1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\c1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\c2.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\c2.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\ive1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\ive1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\j.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\j.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jan1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\jan1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\jo1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo2.png\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\jo2.png\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo3.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\jo3.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo4.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\jo4.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo5.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\jo5.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\jo6.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\jo6.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\lee1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\lee1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\lee3.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\lee3.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\new1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\new1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\park1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\park1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\s1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\s1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\suji.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji2.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\suji2.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji4.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\suji4.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji5.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\suji5.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\suji6.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\suji6.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\sun1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\sun1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\y1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\y1.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\y2.jpg\n",
      "c:\\Users\\hOMe_pc\\Code\\AIs\\server\\FlaskTest\\test_folder\\back\\total\\y2.jpg\n"
     ]
    }
   ],
   "source": [
    "face_masking(model_f, image_names ,test_folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS_mrcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
